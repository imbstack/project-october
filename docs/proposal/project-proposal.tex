%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%
%%%%  Project October
%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\documentclass[11pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage[letterpaper,includeheadfoot, top=0.5cm, bottom=3.0cm, right=2.0cm, left=2.0cm]{geometry}
\renewcommand{\familydefault}{\sfdefault}

\usepackage{graphicx}
\usepackage{color}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{hyperref}
\usepackage{subfig}
\usepackage{pdfpages}
\usepackage{amssymb}
\usepackage{url}
\usepackage{listings}

\usepackage{listings} %Code
\lstset{language=C, tabsize=4,framexleftmargin=5mm,breaklines=true}

\begin{document}
%\begin{sf}

\newpage
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{ \includegraphics[scale=0.3]{img/cwru-formal-logo-blue-no-tag.png} }
\vspace*{6cm}
\begin{center}
\Huge  {Project October}\\
\vspace{1cm}
\huge {Read news that you want to read}\\
\vspace{1cm}
\end{center}
%----------------- Names ------------------------
\vfill
\begin{flushright}
\begin{tabular}{ll}
Authors: & Rajesh Cherukuri, Tom Dooner, Mika Little, Brian Stack\\
Project: & Project October\\
Date: & \today
\end{tabular}
\end{flushright}

\newpage
\pagestyle{fancy}
\fancyhf{}

%\fancyhead[L]{\rightmark}
\fancyhead[L]{\small \rm \textit{\rightmark}}
\fancyhead[R]{\small \rm \textbf{\thepage}}


%\fancyfoot[L]{\small \rm \textit{Pie de página - Izquierda}}
%\fancyfoot[R]{\small \rm \textit{Pie de página - Derecha}}
%\fancyfoot[C]{\thepage} %Centro

\renewcommand{\sectionmark}[1]{\markright{\thesection.\ #1}}
\renewcommand{\headrulewidth}{0.5pt}
\renewcommand{\footrulewidth}{0.5pt}

% =============== Index ===============

\tableofcontents
\listoffigures

% =============== Section ===============
\newpage
\section{Abstract}

In modern news aggregation services, such as Reddit, Slashdot, Digg, and Hacker News, longtime members report noticing a marked decrease in quality of discourse as the services gain mainstream attention.
This gradual but irreversible decline caused by the influx of new users dates back to the newsgroup era, when new college students would log in for the first times in September.
After AOL opened newsgroups to the masses, the community standards continued to devolve, according to newsgroup veterans\cite{september}.

The inevitable loss of the longtime members further perpetuates the problem, and causes large numbers of excellent contributors to feel out-of-place in their own community.
We aim to engineer a service that uses technological principles to avoid this, thus improving the user experience and allowing a large community to benefit from thoughtful discourse and interesting articles. \\

\newpage

%----Everything else----%

\section{Project October: Hybrid Recommender System}

Due to the enormous amount of information available online, the need for a highly developed personalization and filtering system is growing permanently.
Recommender systems constitute a specific type of information filtering that attempt to present items according the interests expressed by a user\cite{1}.
Most web recommenders are employed for e-commerce applications or customer adapted websites, which assist users in decision making by providing personalized information \cite{5}, but the same techniques that suggest related items on e-commerce websites can recommend news articles to users who will enjoy reading them.
We believe Project October is the first attempt to apply recommendation techniques to social news aggregation.

\subsection{Background}
It is our hypothesis that recommendation of news sources will provide a scalable community experience that can be tailored to each person's interests.
Providing an automatic, customized, recommendation of articles will prevent the community from being diluted by new users thus preventing the Eternal September phenomenon.
Users that prefer intellectual discourse will automatically be recommended articles and comments that fit such a criteria, and users that prefer simpler entertainment will be recommended such stories.

This proposal discusses an implementation of a hybrid collaborative and content-based filtering approach for a web-based recommender system (``October'').
In particular, we will be linking various news sources and user submitted sources.
The resulting network of user-item relations and associated content features is converted into a unified mathematical model, which is applicable to our underlying neighbor-based prediction algorithm.
By means of various experiments, we demonstrate the influence of supplementary users as well as item features on the prediction accuracy of October, our proposed hybrid recommender. In order to decrease system runtime and to reveal latent user and item relations, we factorize our hybrid model via singular value decomposition (SVD).

For the development and evaluation of our proposed hybrid recommender system, we make use of various news outlets and user recommendations, importing them into a graph database.
Both corpora are joined in a unified mathematical model, which describes the complex network of interdependencies.

\subsection{Intended Audience}
% The audience is power web users that want the most accurate news source possible
\subsection{Requirements}
\subsubsection{Frontend}
The frontend will be a standard social news aggregator, similar to Reddit or Hacker News.
Upon going to the homepage, logged-out users will be presented with a splash page that describes the allure of Project October and offers a registration link.
Users can register for the application by selecting a username and password.

When logged in, users will be presented with their personalized content.
We are modeling the design after the front page of a newspaper -- articles that we judge to be more interesting to a user will be placed in the most prominent positioning, and articles that are less important will fill the side columns and occupy less space.
Users will be able to click on the headline (or associated image, if existent) to be taken to the original news source.

Each news article will feature a link to view the associated comments and it will feature a corner icon of how much credibility (``cred'') a given article possesses.
This is analogous to upvoting in Reddit, except that giving an article cred on October will inform the recommendation engine of your individual preference, rather than directly impacting the weighting of an article by a predefined formula.

\subsubsection{Backend}
% Tom: The backend will use a graph database, yadda yadda
% Raja: Hey! The backend does more than that!!

The backend will contain a recommender system, which will consist of a text classifier for incoming \& existing articles to be indexed into a graph database, a learning algorithm to combine what the recommender has learned about the user with the index information, and finally an API to receive queries and return results. The text classifier will be a combination of Latent Semantic Analysis with Singular Value Decomposition and Latent Dirchlet Allocation \ref{lda}, allowing for the clustering of learned topics to create categories of topics while maintaining coherence to produce an index similar to that formed by human judgement. As for the learning algorithm, we will be using a custom bayesian framework \ref{bayesian} that will allow for weighting based on a particular user's current interest instead of a stored calculated interest or utilizing the general population's interests.
Finally, the method of receiving queries and returning results will utilize an API, which is discussed in the following section.

Essentially the approach works as follows: 
    \begin{enumerate}
        \item October predicts the user’s authentic news interests regardless of the news trend, using the user’s clicks in each past time period
        \item Predictions made with data in a series of past time periods are combined to gain an accurate prediction of the user’s authentic news interests
        \item October predicts the user’s current interests by combining their authentic news interests and the current news trend in the cluster the user belongs to within the property graph.
    \end{enumerate}
    
\subsubsection{Frontend/Backend API}
October will employ an API to promote separation between the frontend and the backend recommender system.
This will provide a clear interface and facilitate easy simultaneous development of both parts of October.

To implement the API, we will use Apache Thrift, an Interface Description Language originally developed by Facebook\cite{thrift}.
The essence of the API is simple, featuring primarily two types of calls:
\begin{description}
\item[Give recommendations for user $n$]
This is the main output from the backend, returning recommended news stories or comments for a given user.
Ancillary parameters will be added to this to facilitate the frontend placement of articles, e.g. the recommendation confidence and individual article weightings.
\item[User took action $n$]
This is the main input to the backend, allowing it to adjust recommendations according to user action.
The parameters to this API call can be of many types. For example, "User commented on article \#$n$", "User gave cred to comment \#$n$", and "User visited link \#$n$" are all valid parameters for this API call.
\end{description}

\subsection{Project Management}
We will manage the project using agile development strategies.

\subsubsection{Agile Development}
In order to schedule work, we have employed Pivotal Tracker, an online task management solution.
From the queue, we will assign tasks as we finish previous tasks.
The work naturally fits into two main categories -- frontend and backend.
Work relating to each category will be assigned to the same people until we make enough progress to cross between teams at will.
At least until that point, Brian and Rajesh will work on the backend while Tom and Mika create the frontend.

\subsubsection{Scrum}
We will meet every Monday, Wednesday, and Friday at 3:55pm to have a short meeting to discuss the current progress.

\subsubsection{Iterations}
% We will have iterations of one week in duration
% Perhaps discuss the actual plans for the next few iterations?









% ============= References ==============
\newpage
\newpage
\begin{thebibliography}{6}
  \bibitem{1} Gediminas Adomavicius , Alexander Tuzhilin, \textit{Toward the Next Generation of Recommender Systems: A Survey of the State-of-the-Art and Possible Extensions}, IEEE Transactions on Knowledge and Data Engineering, v.17 n.6, p.734-749, June 2005  [doi>10.1109/TKDE.2005.99]
  \bibitem{5} Greg Linden , Brent Smith , Jeremy York, \textit{Amazon.com Recommendations: Item-to-Item Collaborative Filtering}, IEEE Internet Computing, v.7 n.1, p.76-80, January 2003  [doi>10.1109/MIC.2003.1167344]
  \bibitem{bayesian} Jensen, V. \textit{Bayesian Networks and Decision Graphs}. Springer, 2001
  \bibitem{lda} Arthur Asuncion, Padhraic Smyth, Max Welling. \textit{Asynchronous Distributed Learning of Topic Models}. NIPS 2008. 
  \bibitem{september} \url{http://en.wikipedia.org/wiki/Eternal\_September}
  \bibitem{thrift} \url{http://en.wikipedia.org/wiki/Apache\_Thrift}
\end{thebibliography}

% ============= Database Schematic ==============
\begin{figure}
\centering
\includegraphics{db_diagram.pdf}
\caption{Frontend Database Relational Diagram}
\label{fig:database}
\end{figure}

% ============= FIN ==============

\end{document}
